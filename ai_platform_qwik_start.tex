\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    
    \usepackage{iftex}
    \ifPDFTeX
    	\usepackage[T1]{fontenc}
    	\usepackage{mathpazo}
    \else
    	\usepackage{fontspec}
    \fi

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{ai\_platform\_qwik\_start}
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb. 
    \makeatletter
        \newbox\Wrappedcontinuationbox 
        \newbox\Wrappedvisiblespacebox 
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}} 
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}} 
        \newcommand*\Wrappedcontinuationindent {3ex } 
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox} 
        % Take advantage of the already applied Pygments mark-up to insert 
        % potential linebreaks for TeX processing. 
        %        {, <, #, %, $, ' and ": go to next line. 
        %        _, }, ^, &, >, - and ~: stay at end of broken line. 
        % Use of \textquotesingle for straight quote. 
        \newcommand*\Wrappedbreaksatspecials {% 
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}% 
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}% 
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}% 
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}% 
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}% 
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}% 
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}% 
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}% 
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}% 
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}% 
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}% 
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}% 
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}% 
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}% 
        } 
        % Some characters . , ; ? ! / are not pygmentized. 
        % This macro makes them "active" and they will insert potential linebreaks 
        \newcommand*\Wrappedbreaksatpunct {% 
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}% 
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}% 
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}% 
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}% 
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}% 
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}% 
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}% 
            \catcode`\.\active
            \catcode`\,\active 
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active 
            \lccode`\~`\~ 	
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%
        
        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active 	
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}
    
    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \hypertarget{ai-platform-qwik-start}{%
\subsection{AI Platform: Qwik Start}\label{ai-platform-qwik-start}}

This lab gives you an introductory, end-to-end experience of training
and prediction on AI Platform. The lab will use a census dataset to:

\begin{itemize}
\tightlist
\item
  Create a TensorFlow 2.x training application and validate it locally.
\item
  Run your training job on a single worker instance in the cloud.
\item
  Deploy a model to support prediction.
\item
  Request an online prediction and see the response.
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{os}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{step-1-get-your-training-data}{%
\subsubsection{Step 1: Get your training
data}\label{step-1-get-your-training-data}}

The relevant data files, adult.data and adult.test, are hosted in a
public Cloud Storage bucket.

You can read the files directly from Cloud Storage or copy them to your
local environment. For this lab you will download the samples for local
training, and later upload them to your own Cloud Storage bucket for
cloud training.

Run the following command to download the data to a local file directory
and set variables that point to the downloaded data files:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{bash}

mkdir data
gsutil \PYZhy{}m cp gs://cloud\PYZhy{}samples\PYZhy{}data/ml\PYZhy{}engine/census/data/* data/
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Copying gs://cloud-samples-data/ml-engine/census/data/adult.data.csv{\ldots}
Copying gs://cloud-samples-data/ml-engine/census/data/test.json{\ldots}
Copying gs://cloud-samples-data/ml-engine/census/data/adult.test.csv{\ldots}
Copying gs://cloud-samples-data/ml-engine/census/data/census.train.csv{\ldots}
Copying gs://cloud-samples-data/ml-engine/census/data/census.test.csv{\ldots}
Copying gs://cloud-samples-data/ml-engine/census/data/test.csv{\ldots}
/ [6/6 files][ 10.7 MiB/ 10.7 MiB] 100\% Done
Operation completed over 6 objects/10.7 MiB.
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{bash}

export TRAIN\PYZus{}DATA=\PYZdl{}(pwd)/data/adult.data.csv
export EVAL\PYZus{}DATA=\PYZdl{}(pwd)/data/adult.test.csv
\end{Verbatim}
\end{tcolorbox}

    Inspect what the data looks like by looking at the first couple of rows:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{bash}

head data/adult.data.csv
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
39, State-gov, 77516, Bachelors, 13, Never-married, Adm-clerical, Not-in-family,
White, Male, 2174, 0, 40, United-States, <=50K
50, Self-emp-not-inc, 83311, Bachelors, 13, Married-civ-spouse, Exec-managerial,
Husband, White, Male, 0, 0, 13, United-States, <=50K
38, Private, 215646, HS-grad, 9, Divorced, Handlers-cleaners, Not-in-family,
White, Male, 0, 0, 40, United-States, <=50K
53, Private, 234721, 11th, 7, Married-civ-spouse, Handlers-cleaners, Husband,
Black, Male, 0, 0, 40, United-States, <=50K
28, Private, 338409, Bachelors, 13, Married-civ-spouse, Prof-specialty, Wife,
Black, Female, 0, 0, 40, Cuba, <=50K
37, Private, 284582, Masters, 14, Married-civ-spouse, Exec-managerial, Wife,
White, Female, 0, 0, 40, United-States, <=50K
49, Private, 160187, 9th, 5, Married-spouse-absent, Other-service, Not-in-
family, Black, Female, 0, 0, 16, Jamaica, <=50K
52, Self-emp-not-inc, 209642, HS-grad, 9, Married-civ-spouse, Exec-managerial,
Husband, White, Male, 0, 0, 45, United-States, >50K
31, Private, 45781, Masters, 14, Never-married, Prof-specialty, Not-in-family,
White, Female, 14084, 0, 50, United-States, >50K
42, Private, 159449, Bachelors, 13, Married-civ-spouse, Exec-managerial,
Husband, White, Male, 5178, 0, 40, United-States, >50K
    \end{Verbatim}

    \hypertarget{step-2-run-a-local-training-job}{%
\subsubsection{Step 2: Run a local training
job}\label{step-2-run-a-local-training-job}}

A local training job loads your Python training program and starts a
training process in an environment that's similar to that of a live
Cloud AI Platform cloud training job.

    \hypertarget{step-2.1-create-files-to-hold-the-python-program}{%
\paragraph{Step 2.1: Create files to hold the Python
program}\label{step-2.1-create-files-to-hold-the-python-program}}

To do that, let's create three files. The first, called util.py, will
contain utility methods for cleaning and preprocessing the data, as well
as performing any feature engineering needed by transforming and
normalizing the data.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{bash}
mkdir \PYZhy{}p trainer
touch trainer/\PYZus{}\PYZus{}init\PYZus{}\PYZus{}.py
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}writefile} trainer/util.py
\PY{k+kn}{from} \PY{n+nn}{\PYZus{}\PYZus{}future\PYZus{}\PYZus{}} \PY{k+kn}{import} \PY{n}{absolute\PYZus{}import}
\PY{k+kn}{from} \PY{n+nn}{\PYZus{}\PYZus{}future\PYZus{}\PYZus{}} \PY{k+kn}{import} \PY{n}{division}
\PY{k+kn}{from} \PY{n+nn}{\PYZus{}\PYZus{}future\PYZus{}\PYZus{}} \PY{k+kn}{import} \PY{n}{print\PYZus{}function}

\PY{k+kn}{import} \PY{n+nn}{os}
\PY{k+kn}{from} \PY{n+nn}{six}\PY{n+nn}{.}\PY{n+nn}{moves} \PY{k+kn}{import} \PY{n}{urllib}
\PY{k+kn}{import} \PY{n+nn}{tempfile}

\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
\PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}

\PY{c+c1}{\PYZsh{} Storage directory}
\PY{n}{DATA\PYZus{}DIR} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{tempfile}\PY{o}{.}\PY{n}{gettempdir}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{census\PYZus{}data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Download options.}
\PY{n}{DATA\PYZus{}URL} \PY{o}{=} \PY{p}{(}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{https://storage.googleapis.com/cloud\PYZhy{}samples\PYZhy{}data/ai\PYZhy{}platform/census}\PY{l+s+s1}{\PYZsq{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{TRAINING\PYZus{}FILE} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adult.data.csv}\PY{l+s+s1}{\PYZsq{}}
\PY{n}{EVAL\PYZus{}FILE} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adult.test.csv}\PY{l+s+s1}{\PYZsq{}}
\PY{n}{TRAINING\PYZus{}URL} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s1}{/}\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{DATA\PYZus{}URL}\PY{p}{,} \PY{n}{TRAINING\PYZus{}FILE}\PY{p}{)}
\PY{n}{EVAL\PYZus{}URL} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s1}{/}\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{DATA\PYZus{}URL}\PY{p}{,} \PY{n}{EVAL\PYZus{}FILE}\PY{p}{)}

\PY{c+c1}{\PYZsh{} These are the features in the dataset.}
\PY{c+c1}{\PYZsh{} Dataset information: https://archive.ics.uci.edu/ml/datasets/census+income}
\PY{n}{\PYZus{}CSV\PYZus{}COLUMNS} \PY{o}{=} \PY{p}{[}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{workclass}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{fnlwgt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{education}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{education\PYZus{}num}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{marital\PYZus{}status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occupation}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relationship}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{race}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gender}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{capital\PYZus{}gain}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{capital\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hours\PYZus{}per\PYZus{}week}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{native\PYZus{}country}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{income\PYZus{}bracket}\PY{l+s+s1}{\PYZsq{}}
\PY{p}{]}

\PY{c+c1}{\PYZsh{} This is the label (target) we want to predict.}
\PY{n}{\PYZus{}LABEL\PYZus{}COLUMN} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{income\PYZus{}bracket}\PY{l+s+s1}{\PYZsq{}}

\PY{c+c1}{\PYZsh{} These are columns we will not use as features for training. There are many}
\PY{c+c1}{\PYZsh{} reasons not to use certain attributes of data for training. Perhaps their}
\PY{c+c1}{\PYZsh{} values are noisy or inconsistent, or perhaps they encode bias that we do not}
\PY{c+c1}{\PYZsh{} want our model to learn. For a deep dive into the features of this Census}
\PY{c+c1}{\PYZsh{} dataset and the challenges they pose, see the Introduction to ML Fairness}
\PY{c+c1}{\PYZsh{} Notebook: https://colab.research.google.com/github/google/eng\PYZhy{}edu/blob}
\PY{c+c1}{\PYZsh{} /master/ml/cc/exercises/intro\PYZus{}to\PYZus{}fairness.ipynb}
\PY{n}{UNUSED\PYZus{}COLUMNS} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{fnlwgt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{education}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gender}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

\PY{n}{\PYZus{}CATEGORICAL\PYZus{}TYPES} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{workclass}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{pd}\PY{o}{.}\PY{n}{api}\PY{o}{.}\PY{n}{types}\PY{o}{.}\PY{n}{CategoricalDtype}\PY{p}{(}\PY{n}{categories}\PY{o}{=}\PY{p}{[}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Federal\PYZhy{}gov}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Local\PYZhy{}gov}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Never\PYZhy{}worked}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Private}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Self\PYZhy{}emp\PYZhy{}inc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Self\PYZhy{}emp\PYZhy{}not\PYZhy{}inc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{State\PYZhy{}gov}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Without\PYZhy{}pay}\PY{l+s+s1}{\PYZsq{}}
    \PY{p}{]}\PY{p}{)}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{marital\PYZus{}status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{pd}\PY{o}{.}\PY{n}{api}\PY{o}{.}\PY{n}{types}\PY{o}{.}\PY{n}{CategoricalDtype}\PY{p}{(}\PY{n}{categories}\PY{o}{=}\PY{p}{[}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Divorced}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Married\PYZhy{}AF\PYZhy{}spouse}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Married\PYZhy{}civ\PYZhy{}spouse}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Married\PYZhy{}spouse\PYZhy{}absent}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Never\PYZhy{}married}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Separated}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Widowed}\PY{l+s+s1}{\PYZsq{}}
    \PY{p}{]}\PY{p}{)}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occupation}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{pd}\PY{o}{.}\PY{n}{api}\PY{o}{.}\PY{n}{types}\PY{o}{.}\PY{n}{CategoricalDtype}\PY{p}{(}\PY{p}{[}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Adm\PYZhy{}clerical}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Armed\PYZhy{}Forces}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Craft\PYZhy{}repair}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Exec\PYZhy{}managerial}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Farming\PYZhy{}fishing}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Handlers\PYZhy{}cleaners}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Machine\PYZhy{}op\PYZhy{}inspct}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Other\PYZhy{}service}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Priv\PYZhy{}house\PYZhy{}serv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Prof\PYZhy{}specialty}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Protective\PYZhy{}serv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Sales}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Tech\PYZhy{}support}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Transport\PYZhy{}moving}\PY{l+s+s1}{\PYZsq{}}
    \PY{p}{]}\PY{p}{)}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relationship}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{pd}\PY{o}{.}\PY{n}{api}\PY{o}{.}\PY{n}{types}\PY{o}{.}\PY{n}{CategoricalDtype}\PY{p}{(}\PY{n}{categories}\PY{o}{=}\PY{p}{[}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Husband}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Not\PYZhy{}in\PYZhy{}family}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Other\PYZhy{}relative}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Own\PYZhy{}child}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Unmarried}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Wife}\PY{l+s+s1}{\PYZsq{}}
    \PY{p}{]}\PY{p}{)}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{race}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{pd}\PY{o}{.}\PY{n}{api}\PY{o}{.}\PY{n}{types}\PY{o}{.}\PY{n}{CategoricalDtype}\PY{p}{(}\PY{n}{categories}\PY{o}{=}\PY{p}{[}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Amer\PYZhy{}Indian\PYZhy{}Eskimo}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Asian\PYZhy{}Pac\PYZhy{}Islander}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Black}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Other}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{White}\PY{l+s+s1}{\PYZsq{}}
    \PY{p}{]}\PY{p}{)}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{native\PYZus{}country}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{pd}\PY{o}{.}\PY{n}{api}\PY{o}{.}\PY{n}{types}\PY{o}{.}\PY{n}{CategoricalDtype}\PY{p}{(}\PY{n}{categories}\PY{o}{=}\PY{p}{[}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cambodia}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Canada}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{China}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Columbia}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cuba}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Dominican\PYZhy{}Republic}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Ecuador}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{El\PYZhy{}Salvador}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{England}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{France}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Germany}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Greece}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Guatemala}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Haiti}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Holand\PYZhy{}Netherlands}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Honduras}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Hong}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Hungary}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{India}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Iran}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Ireland}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Italy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Jamaica}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Japan}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Laos}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mexico}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Nicaragua}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Outlying\PYZhy{}US(Guam\PYZhy{}USVI\PYZhy{}etc)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Peru}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Philippines}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Poland}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Portugal}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Puerto\PYZhy{}Rico}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Scotland}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{South}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Taiwan}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Thailand}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Trinadad\PYZam{}Tobago}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{United\PYZhy{}States}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Vietnam}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Yugoslavia}\PY{l+s+s1}{\PYZsq{}}
    \PY{p}{]}\PY{p}{)}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{income\PYZus{}bracket}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{pd}\PY{o}{.}\PY{n}{api}\PY{o}{.}\PY{n}{types}\PY{o}{.}\PY{n}{CategoricalDtype}\PY{p}{(}\PY{n}{categories}\PY{o}{=}\PY{p}{[}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZlt{}=50K}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZgt{}50K}\PY{l+s+s1}{\PYZsq{}}
    \PY{p}{]}\PY{p}{)}
\PY{p}{\PYZcb{}}


\PY{k}{def} \PY{n+nf}{\PYZus{}download\PYZus{}and\PYZus{}clean\PYZus{}file}\PY{p}{(}\PY{n}{filename}\PY{p}{,} \PY{n}{url}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Downloads data from url, and makes changes to match the CSV format.}

\PY{l+s+sd}{    The CSVs may use spaces after the comma delimters (non\PYZhy{}standard) or include}
\PY{l+s+sd}{    rows which do not represent well\PYZhy{}formed examples. This function strips out}
\PY{l+s+sd}{    some of these problems.}

\PY{l+s+sd}{    Args:}
\PY{l+s+sd}{      filename: filename to save url to}
\PY{l+s+sd}{      url: URL of resource to download}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{n}{temp\PYZus{}file}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{urllib}\PY{o}{.}\PY{n}{request}\PY{o}{.}\PY{n}{urlretrieve}\PY{p}{(}\PY{n}{url}\PY{p}{)}
    \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{io}\PY{o}{.}\PY{n}{gfile}\PY{o}{.}\PY{n}{GFile}\PY{p}{(}\PY{n}{temp\PYZus{}file}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{temp\PYZus{}file\PYZus{}object}\PY{p}{:}
        \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{io}\PY{o}{.}\PY{n}{gfile}\PY{o}{.}\PY{n}{GFile}\PY{p}{(}\PY{n}{filename}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{w}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{file\PYZus{}object}\PY{p}{:}
            \PY{k}{for} \PY{n}{line} \PY{o+ow}{in} \PY{n}{temp\PYZus{}file\PYZus{}object}\PY{p}{:}
                \PY{n}{line} \PY{o}{=} \PY{n}{line}\PY{o}{.}\PY{n}{strip}\PY{p}{(}\PY{p}{)}
                \PY{n}{line} \PY{o}{=} \PY{n}{line}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{, }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                \PY{k}{if} \PY{o+ow}{not} \PY{n}{line} \PY{o+ow}{or} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{line}\PY{p}{:}
                    \PY{k}{continue}
                \PY{k}{if} \PY{n}{line}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                    \PY{n}{line} \PY{o}{=} \PY{n}{line}\PY{p}{[}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
                \PY{n}{line} \PY{o}{+}\PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}
                \PY{n}{file\PYZus{}object}\PY{o}{.}\PY{n}{write}\PY{p}{(}\PY{n}{line}\PY{p}{)}
    \PY{n}{tf}\PY{o}{.}\PY{n}{io}\PY{o}{.}\PY{n}{gfile}\PY{o}{.}\PY{n}{remove}\PY{p}{(}\PY{n}{temp\PYZus{}file}\PY{p}{)}


\PY{k}{def} \PY{n+nf}{download}\PY{p}{(}\PY{n}{data\PYZus{}dir}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Downloads census data if it is not already present.}

\PY{l+s+sd}{    Args:}
\PY{l+s+sd}{      data\PYZus{}dir: directory where we will access/save the census data}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{n}{tf}\PY{o}{.}\PY{n}{io}\PY{o}{.}\PY{n}{gfile}\PY{o}{.}\PY{n}{makedirs}\PY{p}{(}\PY{n}{data\PYZus{}dir}\PY{p}{)}

    \PY{n}{training\PYZus{}file\PYZus{}path} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{data\PYZus{}dir}\PY{p}{,} \PY{n}{TRAINING\PYZus{}FILE}\PY{p}{)}
    \PY{k}{if} \PY{o+ow}{not} \PY{n}{tf}\PY{o}{.}\PY{n}{io}\PY{o}{.}\PY{n}{gfile}\PY{o}{.}\PY{n}{exists}\PY{p}{(}\PY{n}{training\PYZus{}file\PYZus{}path}\PY{p}{)}\PY{p}{:}
        \PY{n}{\PYZus{}download\PYZus{}and\PYZus{}clean\PYZus{}file}\PY{p}{(}\PY{n}{training\PYZus{}file\PYZus{}path}\PY{p}{,} \PY{n}{TRAINING\PYZus{}URL}\PY{p}{)}

    \PY{n}{eval\PYZus{}file\PYZus{}path} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{data\PYZus{}dir}\PY{p}{,} \PY{n}{EVAL\PYZus{}FILE}\PY{p}{)}
    \PY{k}{if} \PY{o+ow}{not} \PY{n}{tf}\PY{o}{.}\PY{n}{io}\PY{o}{.}\PY{n}{gfile}\PY{o}{.}\PY{n}{exists}\PY{p}{(}\PY{n}{eval\PYZus{}file\PYZus{}path}\PY{p}{)}\PY{p}{:}
        \PY{n}{\PYZus{}download\PYZus{}and\PYZus{}clean\PYZus{}file}\PY{p}{(}\PY{n}{eval\PYZus{}file\PYZus{}path}\PY{p}{,} \PY{n}{EVAL\PYZus{}URL}\PY{p}{)}

    \PY{k}{return} \PY{n}{training\PYZus{}file\PYZus{}path}\PY{p}{,} \PY{n}{eval\PYZus{}file\PYZus{}path}


\PY{k}{def} \PY{n+nf}{preprocess}\PY{p}{(}\PY{n}{dataframe}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Converts categorical features to numeric. Removes unused columns.}

\PY{l+s+sd}{    Args:}
\PY{l+s+sd}{      dataframe: Pandas dataframe with raw data}

\PY{l+s+sd}{    Returns:}
\PY{l+s+sd}{      Dataframe with preprocessed data}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{n}{dataframe} \PY{o}{=} \PY{n}{dataframe}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{n}{UNUSED\PYZus{}COLUMNS}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Convert integer valued (numeric) columns to floating point}
    \PY{n}{numeric\PYZus{}columns} \PY{o}{=} \PY{n}{dataframe}\PY{o}{.}\PY{n}{select\PYZus{}dtypes}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{int64}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{columns}
    \PY{n}{dataframe}\PY{p}{[}\PY{n}{numeric\PYZus{}columns}\PY{p}{]} \PY{o}{=} \PY{n}{dataframe}\PY{p}{[}\PY{n}{numeric\PYZus{}columns}\PY{p}{]}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{float32}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Convert categorical columns to numeric}
    \PY{n}{cat\PYZus{}columns} \PY{o}{=} \PY{n}{dataframe}\PY{o}{.}\PY{n}{select\PYZus{}dtypes}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{object}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{columns}
    \PY{n}{dataframe}\PY{p}{[}\PY{n}{cat\PYZus{}columns}\PY{p}{]} \PY{o}{=} \PY{n}{dataframe}\PY{p}{[}\PY{n}{cat\PYZus{}columns}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{.}\PY{n}{astype}\PY{p}{(}
        \PY{n}{\PYZus{}CATEGORICAL\PYZus{}TYPES}\PY{p}{[}\PY{n}{x}\PY{o}{.}\PY{n}{name}\PY{p}{]}\PY{p}{)}\PY{p}{)}
    \PY{n}{dataframe}\PY{p}{[}\PY{n}{cat\PYZus{}columns}\PY{p}{]} \PY{o}{=} \PY{n}{dataframe}\PY{p}{[}\PY{n}{cat\PYZus{}columns}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{.}\PY{n}{cat}\PY{o}{.}\PY{n}{codes}\PY{p}{)}
    \PY{k}{return} \PY{n}{dataframe}


\PY{k}{def} \PY{n+nf}{standardize}\PY{p}{(}\PY{n}{dataframe}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Scales numerical columns using their means and standard deviation to get}
\PY{l+s+sd}{    z\PYZhy{}scores: the mean of each numerical column becomes 0, and the standard}
\PY{l+s+sd}{    deviation becomes 1. This can help the model converge during training.}

\PY{l+s+sd}{    Args:}
\PY{l+s+sd}{      dataframe: Pandas dataframe}

\PY{l+s+sd}{    Returns:}
\PY{l+s+sd}{      Input dataframe with the numerical columns scaled to z\PYZhy{}scores}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{n}{dtypes} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{zip}\PY{p}{(}\PY{n}{dataframe}\PY{o}{.}\PY{n}{dtypes}\PY{o}{.}\PY{n}{index}\PY{p}{,} \PY{n+nb}{map}\PY{p}{(}\PY{n+nb}{str}\PY{p}{,} \PY{n}{dataframe}\PY{o}{.}\PY{n}{dtypes}\PY{p}{)}\PY{p}{)}\PY{p}{)}
    \PY{c+c1}{\PYZsh{} Normalize numeric columns.}
    \PY{k}{for} \PY{n}{column}\PY{p}{,} \PY{n}{dtype} \PY{o+ow}{in} \PY{n}{dtypes}\PY{p}{:}
        \PY{k}{if} \PY{n}{dtype} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{float32}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
            \PY{n}{dataframe}\PY{p}{[}\PY{n}{column}\PY{p}{]} \PY{o}{\PYZhy{}}\PY{o}{=} \PY{n}{dataframe}\PY{p}{[}\PY{n}{column}\PY{p}{]}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
            \PY{n}{dataframe}\PY{p}{[}\PY{n}{column}\PY{p}{]} \PY{o}{/}\PY{o}{=} \PY{n}{dataframe}\PY{p}{[}\PY{n}{column}\PY{p}{]}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
    \PY{k}{return} \PY{n}{dataframe}


\PY{k}{def} \PY{n+nf}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Loads data into preprocessed (train\PYZus{}x, train\PYZus{}y, eval\PYZus{}y, eval\PYZus{}y)}
\PY{l+s+sd}{    dataframes.}

\PY{l+s+sd}{    Returns:}
\PY{l+s+sd}{      A tuple (train\PYZus{}x, train\PYZus{}y, eval\PYZus{}x, eval\PYZus{}y), where train\PYZus{}x and eval\PYZus{}x are}
\PY{l+s+sd}{      Pandas dataframes with features for training and train\PYZus{}y and eval\PYZus{}y are}
\PY{l+s+sd}{      numpy arrays with the corresponding labels.}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{c+c1}{\PYZsh{} Download Census dataset: Training and eval csv files.}
    \PY{n}{training\PYZus{}file\PYZus{}path}\PY{p}{,} \PY{n}{eval\PYZus{}file\PYZus{}path} \PY{o}{=} \PY{n}{download}\PY{p}{(}\PY{n}{DATA\PYZus{}DIR}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} This census data uses the value \PYZsq{}?\PYZsq{} for missing entries. We use}
    \PY{c+c1}{\PYZsh{} na\PYZus{}values to}
    \PY{c+c1}{\PYZsh{} find ? and set it to NaN.}
    \PY{c+c1}{\PYZsh{} https://pandas.pydata.org/pandas\PYZhy{}docs/stable/generated/pandas.read\PYZus{}csv}
    \PY{c+c1}{\PYZsh{} .html}
    \PY{n}{train\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{training\PYZus{}file\PYZus{}path}\PY{p}{,} \PY{n}{names}\PY{o}{=}\PY{n}{\PYZus{}CSV\PYZus{}COLUMNS}\PY{p}{,}
                           \PY{n}{na\PYZus{}values}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{?}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{eval\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{eval\PYZus{}file\PYZus{}path}\PY{p}{,} \PY{n}{names}\PY{o}{=}\PY{n}{\PYZus{}CSV\PYZus{}COLUMNS}\PY{p}{,} \PY{n}{na\PYZus{}values}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{?}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

    \PY{n}{train\PYZus{}df} \PY{o}{=} \PY{n}{preprocess}\PY{p}{(}\PY{n}{train\PYZus{}df}\PY{p}{)}
    \PY{n}{eval\PYZus{}df} \PY{o}{=} \PY{n}{preprocess}\PY{p}{(}\PY{n}{eval\PYZus{}df}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Split train and eval data with labels. The pop method copies and removes}
    \PY{c+c1}{\PYZsh{} the label column from the dataframe.}
    \PY{n}{train\PYZus{}x}\PY{p}{,} \PY{n}{train\PYZus{}y} \PY{o}{=} \PY{n}{train\PYZus{}df}\PY{p}{,} \PY{n}{train\PYZus{}df}\PY{o}{.}\PY{n}{pop}\PY{p}{(}\PY{n}{\PYZus{}LABEL\PYZus{}COLUMN}\PY{p}{)}
    \PY{n}{eval\PYZus{}x}\PY{p}{,} \PY{n}{eval\PYZus{}y} \PY{o}{=} \PY{n}{eval\PYZus{}df}\PY{p}{,} \PY{n}{eval\PYZus{}df}\PY{o}{.}\PY{n}{pop}\PY{p}{(}\PY{n}{\PYZus{}LABEL\PYZus{}COLUMN}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Join train\PYZus{}x and eval\PYZus{}x to normalize on overall means and standard}
    \PY{c+c1}{\PYZsh{} deviations. Then separate them again.}
    \PY{n}{all\PYZus{}x} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{concat}\PY{p}{(}\PY{p}{[}\PY{n}{train\PYZus{}x}\PY{p}{,} \PY{n}{eval\PYZus{}x}\PY{p}{]}\PY{p}{,} \PY{n}{keys}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{eval}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
    \PY{n}{all\PYZus{}x} \PY{o}{=} \PY{n}{standardize}\PY{p}{(}\PY{n}{all\PYZus{}x}\PY{p}{)}
    \PY{n}{train\PYZus{}x}\PY{p}{,} \PY{n}{eval\PYZus{}x} \PY{o}{=} \PY{n}{all\PYZus{}x}\PY{o}{.}\PY{n}{xs}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{n}{all\PYZus{}x}\PY{o}{.}\PY{n}{xs}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{eval}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Reshape label columns for use with tf.data.Dataset}
    \PY{n}{train\PYZus{}y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{asarray}\PY{p}{(}\PY{n}{train\PYZus{}y}\PY{p}{)}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{float32}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
    \PY{n}{eval\PYZus{}y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{asarray}\PY{p}{(}\PY{n}{eval\PYZus{}y}\PY{p}{)}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{float32}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}

    \PY{k}{return} \PY{n}{train\PYZus{}x}\PY{p}{,} \PY{n}{train\PYZus{}y}\PY{p}{,} \PY{n}{eval\PYZus{}x}\PY{p}{,} \PY{n}{eval\PYZus{}y}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Writing trainer/util.py
    \end{Verbatim}

    The second file, called model.py, defines the input function and the
model architecture. In this example, we use tf.data API for the data
pipeline and create the model using the Keras Sequential API. We define
a DNN with an input layer and 3 additonal layers using the Relu
activation function. Since the task is a binary classification, the
output layer uses the sigmoid activation.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}writefile} trainer/model.py
\PY{k+kn}{from} \PY{n+nn}{\PYZus{}\PYZus{}future\PYZus{}\PYZus{}} \PY{k+kn}{import} \PY{n}{absolute\PYZus{}import}
\PY{k+kn}{from} \PY{n+nn}{\PYZus{}\PYZus{}future\PYZus{}\PYZus{}} \PY{k+kn}{import} \PY{n}{division}
\PY{k+kn}{from} \PY{n+nn}{\PYZus{}\PYZus{}future\PYZus{}\PYZus{}} \PY{k+kn}{import} \PY{n}{print\PYZus{}function}

\PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}


\PY{k}{def} \PY{n+nf}{input\PYZus{}fn}\PY{p}{(}\PY{n}{features}\PY{p}{,} \PY{n}{labels}\PY{p}{,} \PY{n}{shuffle}\PY{p}{,} \PY{n}{num\PYZus{}epochs}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Generates an input function to be used for model training.}

\PY{l+s+sd}{    Args:}
\PY{l+s+sd}{      features: numpy array of features used for training or inference}
\PY{l+s+sd}{      labels: numpy array of labels for each example}
\PY{l+s+sd}{      shuffle: boolean for whether to shuffle the data or not (set True for}
\PY{l+s+sd}{        training, False for evaluation)}
\PY{l+s+sd}{      num\PYZus{}epochs: number of epochs to provide the data for}
\PY{l+s+sd}{      batch\PYZus{}size: batch size for training}

\PY{l+s+sd}{    Returns:}
\PY{l+s+sd}{      A tf.data.Dataset that can provide data to the Keras model for training or}
\PY{l+s+sd}{        evaluation}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{k}{if} \PY{n}{labels} \PY{o+ow}{is} \PY{k+kc}{None}\PY{p}{:}
        \PY{n}{inputs} \PY{o}{=} \PY{n}{features}
    \PY{k}{else}\PY{p}{:}
        \PY{n}{inputs} \PY{o}{=} \PY{p}{(}\PY{n}{features}\PY{p}{,} \PY{n}{labels}\PY{p}{)}
    \PY{n}{dataset} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{Dataset}\PY{o}{.}\PY{n}{from\PYZus{}tensor\PYZus{}slices}\PY{p}{(}\PY{n}{inputs}\PY{p}{)}

    \PY{k}{if} \PY{n}{shuffle}\PY{p}{:}
        \PY{n}{dataset} \PY{o}{=} \PY{n}{dataset}\PY{o}{.}\PY{n}{shuffle}\PY{p}{(}\PY{n}{buffer\PYZus{}size}\PY{o}{=}\PY{n+nb}{len}\PY{p}{(}\PY{n}{features}\PY{p}{)}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} We call repeat after shuffling, rather than before, to prevent separate}
    \PY{c+c1}{\PYZsh{} epochs from blending together.}
    \PY{n}{dataset} \PY{o}{=} \PY{n}{dataset}\PY{o}{.}\PY{n}{repeat}\PY{p}{(}\PY{n}{num\PYZus{}epochs}\PY{p}{)}
    \PY{n}{dataset} \PY{o}{=} \PY{n}{dataset}\PY{o}{.}\PY{n}{batch}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{)}
    \PY{k}{return} \PY{n}{dataset}


\PY{k}{def} \PY{n+nf}{create\PYZus{}keras\PYZus{}model}\PY{p}{(}\PY{n}{input\PYZus{}dim}\PY{p}{,} \PY{n}{learning\PYZus{}rate}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Creates Keras Model for Binary Classification.}

\PY{l+s+sd}{    The single output node + Sigmoid activation makes this a Logistic}
\PY{l+s+sd}{    Regression.}

\PY{l+s+sd}{    Args:}
\PY{l+s+sd}{      input\PYZus{}dim: How many features the input has}
\PY{l+s+sd}{      learning\PYZus{}rate: Learning rate for training}

\PY{l+s+sd}{    Returns:}
\PY{l+s+sd}{      The compiled Keras model (still needs to be trained)}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{n}{Dense} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{keras}\PY{o}{.}\PY{n}{layers}\PY{o}{.}\PY{n}{Dense}
    \PY{n}{model} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{keras}\PY{o}{.}\PY{n}{Sequential}\PY{p}{(}
        \PY{p}{[}
            \PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{relu}\PY{p}{,} \PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                  \PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{n}{input\PYZus{}dim}\PY{p}{,}\PY{p}{)}\PY{p}{)}\PY{p}{,}
            \PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{75}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{relu}\PY{p}{)}\PY{p}{,}
            \PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{relu}\PY{p}{)}\PY{p}{,}
            \PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{25}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{relu}\PY{p}{)}\PY{p}{,}
            \PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{sigmoid}\PY{p}{)}
        \PY{p}{]}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Custom Optimizer:}
    \PY{c+c1}{\PYZsh{} https://www.tensorflow.org/api\PYZus{}docs/python/tf/train/RMSPropOptimizer}
    \PY{n}{optimizer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{keras}\PY{o}{.}\PY{n}{optimizers}\PY{o}{.}\PY{n}{RMSprop}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{n}{learning\PYZus{}rate}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Compile Keras model}
    \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}
        \PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{binary\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{optimizer}\PY{o}{=}\PY{n}{optimizer}\PY{p}{,} \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
    \PY{k}{return} \PY{n}{model}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Writing trainer/model.py
    \end{Verbatim}

    The last file, called task.py, trains on data loaded and preprocessed in
util.py. Using the tf.distribute.MirroredStrategy() scope, it is
possible to train on a distributed fashion. The trained model is then
saved in a TensorFlow SavedModel format.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{8}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}writefile} trainer/task.py
\PY{k+kn}{from} \PY{n+nn}{\PYZus{}\PYZus{}future\PYZus{}\PYZus{}} \PY{k+kn}{import} \PY{n}{absolute\PYZus{}import}
\PY{k+kn}{from} \PY{n+nn}{\PYZus{}\PYZus{}future\PYZus{}\PYZus{}} \PY{k+kn}{import} \PY{n}{division}
\PY{k+kn}{from} \PY{n+nn}{\PYZus{}\PYZus{}future\PYZus{}\PYZus{}} \PY{k+kn}{import} \PY{n}{print\PYZus{}function}

\PY{k+kn}{import} \PY{n+nn}{argparse}
\PY{k+kn}{import} \PY{n+nn}{os}

\PY{k+kn}{from} \PY{n+nn}{.} \PY{k+kn}{import} \PY{n}{model}
\PY{k+kn}{from} \PY{n+nn}{.} \PY{k+kn}{import} \PY{n}{util}

\PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}


\PY{k}{def} \PY{n+nf}{get\PYZus{}args}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Argument parser.}

\PY{l+s+sd}{    Returns:}
\PY{l+s+sd}{      Dictionary of arguments.}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{n}{parser} \PY{o}{=} \PY{n}{argparse}\PY{o}{.}\PY{n}{ArgumentParser}\PY{p}{(}\PY{p}{)}
    \PY{n}{parser}\PY{o}{.}\PY{n}{add\PYZus{}argument}\PY{p}{(}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}job\PYZhy{}dir}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{n+nb}{type}\PY{o}{=}\PY{n+nb}{str}\PY{p}{,}
        \PY{n}{required}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}
        \PY{n}{help}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{local or GCS location for writing checkpoints and exporting }\PY{l+s+s1}{\PYZsq{}}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{models}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{parser}\PY{o}{.}\PY{n}{add\PYZus{}argument}\PY{p}{(}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}num\PYZhy{}epochs}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{n+nb}{type}\PY{o}{=}\PY{n+nb}{int}\PY{p}{,}
        \PY{n}{default}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{,}
        \PY{n}{help}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{number of times to go through the data, default=20}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{parser}\PY{o}{.}\PY{n}{add\PYZus{}argument}\PY{p}{(}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}batch\PYZhy{}size}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{n}{default}\PY{o}{=}\PY{l+m+mi}{128}\PY{p}{,}
        \PY{n+nb}{type}\PY{o}{=}\PY{n+nb}{int}\PY{p}{,}
        \PY{n}{help}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{number of records to read during each training step, default=128}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{parser}\PY{o}{.}\PY{n}{add\PYZus{}argument}\PY{p}{(}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}learning\PYZhy{}rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{n}{default}\PY{o}{=}\PY{l+m+mf}{.01}\PY{p}{,}
        \PY{n+nb}{type}\PY{o}{=}\PY{n+nb}{float}\PY{p}{,}
        \PY{n}{help}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{learning rate for gradient descent, default=.01}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{parser}\PY{o}{.}\PY{n}{add\PYZus{}argument}\PY{p}{(}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}verbosity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{n}{choices}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DEBUG}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ERROR}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{FATAL}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{INFO}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WARN}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
        \PY{n}{default}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{INFO}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{args}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{parser}\PY{o}{.}\PY{n}{parse\PYZus{}known\PYZus{}args}\PY{p}{(}\PY{p}{)}
    \PY{k}{return} \PY{n}{args}


\PY{k}{def} \PY{n+nf}{train\PYZus{}and\PYZus{}evaluate}\PY{p}{(}\PY{n}{args}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Trains and evaluates the Keras model.}

\PY{l+s+sd}{    Uses the Keras model defined in model.py and trains on data loaded and}
\PY{l+s+sd}{    preprocessed in util.py. Saves the trained model in TensorFlow SavedModel}
\PY{l+s+sd}{    format to the path defined in part by the \PYZhy{}\PYZhy{}job\PYZhy{}dir argument.}

\PY{l+s+sd}{    Args:}
\PY{l+s+sd}{      args: dictionary of arguments \PYZhy{} see get\PYZus{}args() for details}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}

    \PY{n}{train\PYZus{}x}\PY{p}{,} \PY{n}{train\PYZus{}y}\PY{p}{,} \PY{n}{eval\PYZus{}x}\PY{p}{,} \PY{n}{eval\PYZus{}y} \PY{o}{=} \PY{n}{util}\PY{o}{.}\PY{n}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} dimensions}
    \PY{n}{num\PYZus{}train\PYZus{}examples}\PY{p}{,} \PY{n}{input\PYZus{}dim} \PY{o}{=} \PY{n}{train\PYZus{}x}\PY{o}{.}\PY{n}{shape}
    \PY{n}{num\PYZus{}eval\PYZus{}examples} \PY{o}{=} \PY{n}{eval\PYZus{}x}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}

    \PY{c+c1}{\PYZsh{} Create the Keras Model}
    \PY{n}{keras\PYZus{}model} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{create\PYZus{}keras\PYZus{}model}\PY{p}{(}
        \PY{n}{input\PYZus{}dim}\PY{o}{=}\PY{n}{input\PYZus{}dim}\PY{p}{,} \PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{n}{args}\PY{o}{.}\PY{n}{learning\PYZus{}rate}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Pass a numpy array by passing DataFrame.values}
    \PY{n}{training\PYZus{}dataset} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{input\PYZus{}fn}\PY{p}{(}
        \PY{n}{features}\PY{o}{=}\PY{n}{train\PYZus{}x}\PY{o}{.}\PY{n}{values}\PY{p}{,}
        \PY{n}{labels}\PY{o}{=}\PY{n}{train\PYZus{}y}\PY{p}{,}
        \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}
        \PY{n}{num\PYZus{}epochs}\PY{o}{=}\PY{n}{args}\PY{o}{.}\PY{n}{num\PYZus{}epochs}\PY{p}{,}
        \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{n}{args}\PY{o}{.}\PY{n}{batch\PYZus{}size}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Pass a numpy array by passing DataFrame.values}
    \PY{n}{validation\PYZus{}dataset} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{input\PYZus{}fn}\PY{p}{(}
        \PY{n}{features}\PY{o}{=}\PY{n}{eval\PYZus{}x}\PY{o}{.}\PY{n}{values}\PY{p}{,}
        \PY{n}{labels}\PY{o}{=}\PY{n}{eval\PYZus{}y}\PY{p}{,}
        \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,}
        \PY{n}{num\PYZus{}epochs}\PY{o}{=}\PY{n}{args}\PY{o}{.}\PY{n}{num\PYZus{}epochs}\PY{p}{,}
        \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{n}{num\PYZus{}eval\PYZus{}examples}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Setup Learning Rate decay.}
    \PY{n}{lr\PYZus{}decay\PYZus{}cb} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{keras}\PY{o}{.}\PY{n}{callbacks}\PY{o}{.}\PY{n}{LearningRateScheduler}\PY{p}{(}
        \PY{k}{lambda} \PY{n}{epoch}\PY{p}{:} \PY{n}{args}\PY{o}{.}\PY{n}{learning\PYZus{}rate} \PY{o}{+} \PY{l+m+mf}{0.02} \PY{o}{*} \PY{p}{(}\PY{l+m+mf}{0.5} \PY{o}{*}\PY{o}{*} \PY{p}{(}\PY{l+m+mi}{1} \PY{o}{+} \PY{n}{epoch}\PY{p}{)}\PY{p}{)}\PY{p}{,}
        \PY{n}{verbose}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Setup TensorBoard callback.}
    \PY{n}{tensorboard\PYZus{}cb} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{keras}\PY{o}{.}\PY{n}{callbacks}\PY{o}{.}\PY{n}{TensorBoard}\PY{p}{(}
        \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{args}\PY{o}{.}\PY{n}{job\PYZus{}dir}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{keras\PYZus{}tensorboard}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,}
        \PY{n}{histogram\PYZus{}freq}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Train model}
    \PY{n}{keras\PYZus{}model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}
        \PY{n}{training\PYZus{}dataset}\PY{p}{,}
        \PY{n}{steps\PYZus{}per\PYZus{}epoch}\PY{o}{=}\PY{n+nb}{int}\PY{p}{(}\PY{n}{num\PYZus{}train\PYZus{}examples} \PY{o}{/} \PY{n}{args}\PY{o}{.}\PY{n}{batch\PYZus{}size}\PY{p}{)}\PY{p}{,}
        \PY{n}{epochs}\PY{o}{=}\PY{n}{args}\PY{o}{.}\PY{n}{num\PYZus{}epochs}\PY{p}{,}
        \PY{n}{validation\PYZus{}data}\PY{o}{=}\PY{n}{validation\PYZus{}dataset}\PY{p}{,}
        \PY{n}{validation\PYZus{}steps}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,}
        \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,}
        \PY{n}{callbacks}\PY{o}{=}\PY{p}{[}\PY{n}{lr\PYZus{}decay\PYZus{}cb}\PY{p}{,} \PY{n}{tensorboard\PYZus{}cb}\PY{p}{]}\PY{p}{)}

    \PY{n}{export\PYZus{}path} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{args}\PY{o}{.}\PY{n}{job\PYZus{}dir}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{keras\PYZus{}export}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{tf}\PY{o}{.}\PY{n}{keras}\PY{o}{.}\PY{n}{models}\PY{o}{.}\PY{n}{save\PYZus{}model}\PY{p}{(}\PY{n}{keras\PYZus{}model}\PY{p}{,} \PY{n}{export\PYZus{}path}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model exported to: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{export\PYZus{}path}\PY{p}{)}\PY{p}{)}



\PY{k}{if} \PY{n+nv+vm}{\PYZus{}\PYZus{}name\PYZus{}\PYZus{}} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZus{}\PYZus{}main\PYZus{}\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
    \PY{n}{strategy} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{distribute}\PY{o}{.}\PY{n}{MirroredStrategy}\PY{p}{(}\PY{p}{)}
    \PY{k}{with} \PY{n}{strategy}\PY{o}{.}\PY{n}{scope}\PY{p}{(}\PY{p}{)}\PY{p}{:}
        \PY{n}{args} \PY{o}{=} \PY{n}{get\PYZus{}args}\PY{p}{(}\PY{p}{)}
        \PY{n}{tf}\PY{o}{.}\PY{n}{compat}\PY{o}{.}\PY{n}{v1}\PY{o}{.}\PY{n}{logging}\PY{o}{.}\PY{n}{set\PYZus{}verbosity}\PY{p}{(}\PY{n}{args}\PY{o}{.}\PY{n}{verbosity}\PY{p}{)}
        \PY{n}{train\PYZus{}and\PYZus{}evaluate}\PY{p}{(}\PY{n}{args}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Writing trainer/task.py
    \end{Verbatim}

    \hypertarget{step-2.2-run-a-training-job-locally-using-the-python-training-program}{%
\paragraph{Step 2.2: Run a training job locally using the Python
training
program}\label{step-2.2-run-a-training-job-locally-using-the-python-training-program}}

\textbf{NOTE} When you run the same training job on AI Platform later in
the lab, you'll see that the command is not much different from the
above.

Specify an output directory and set a MODEL\_DIR variable to hold the
trained model, then run the training job locally by running the
following command (by default, verbose logging is turned off. You can
enable it by setting the --verbosity tag to DEBUG):

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{9}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{bash}

MODEL\PYZus{}DIR=output
gcloud ai\PYZhy{}platform local train \PYZbs{}
    \PYZhy{}\PYZhy{}module\PYZhy{}name trainer.task \PYZbs{}
    \PYZhy{}\PYZhy{}package\PYZhy{}path trainer/ \PYZbs{}
    \PYZhy{}\PYZhy{}job\PYZhy{}dir \PYZdl{}MODEL\PYZus{}DIR \PYZbs{}
    \PYZhy{}\PYZhy{} \PYZbs{}
    \PYZhy{}\PYZhy{}train\PYZhy{}files \PYZdl{}TRAIN\PYZus{}DATA \PYZbs{}
    \PYZhy{}\PYZhy{}eval\PYZhy{}files \PYZdl{}EVAL\PYZus{}DATA \PYZbs{}
    \PYZhy{}\PYZhy{}train\PYZhy{}steps 1000 \PYZbs{}
    \PYZhy{}\PYZhy{}eval\PYZhy{}steps 100
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]

Epoch 00001: LearningRateScheduler reducing learning rate to 0.02.
Epoch 1/20
254/254 [==============================] - 2s 9ms/step - loss: 0.5459 -
accuracy: 0.7888 - val\_loss: 0.3976 - val\_accuracy: 0.8254

Epoch 00002: LearningRateScheduler reducing learning rate to 0.015.
Epoch 2/20
254/254 [==============================] - 2s 7ms/step - loss: 0.3625 -
accuracy: 0.8327 - val\_loss: 0.3852 - val\_accuracy: 0.8065

Epoch 00003: LearningRateScheduler reducing learning rate to 0.0125.
Epoch 3/20
254/254 [==============================] - 2s 6ms/step - loss: 0.3423 -
accuracy: 0.8406 - val\_loss: 0.3308 - val\_accuracy: 0.8492

Epoch 00004: LearningRateScheduler reducing learning rate to 0.01125.
Epoch 4/20
254/254 [==============================] - 2s 7ms/step - loss: 0.3358 -
accuracy: 0.8432 - val\_loss: 0.3281 - val\_accuracy: 0.8437

Epoch 00005: LearningRateScheduler reducing learning rate to 0.010625.
Epoch 5/20
254/254 [==============================] - 2s 9ms/step - loss: 0.3330 -
accuracy: 0.8460 - val\_loss: 0.3273 - val\_accuracy: 0.8443

Epoch 00006: LearningRateScheduler reducing learning rate to 0.0103125.
Epoch 6/20
254/254 [==============================] - 2s 9ms/step - loss: 0.3328 -
accuracy: 0.8463 - val\_loss: 0.3315 - val\_accuracy: 0.8501

Epoch 00007: LearningRateScheduler reducing learning rate to 0.01015625.
Epoch 7/20
254/254 [==============================] - 2s 8ms/step - loss: 0.3291 -
accuracy: 0.8469 - val\_loss: 0.3290 - val\_accuracy: 0.8479

Epoch 00008: LearningRateScheduler reducing learning rate to 0.010078125.
Epoch 8/20
254/254 [==============================] - 2s 7ms/step - loss: 0.3269 -
accuracy: 0.8483 - val\_loss: 0.3370 - val\_accuracy: 0.8484

Epoch 00009: LearningRateScheduler reducing learning rate to 0.0100390625.
Epoch 9/20
254/254 [==============================] - 1s 6ms/step - loss: 0.3279 -
accuracy: 0.8472 - val\_loss: 0.3272 - val\_accuracy: 0.8510

Epoch 00010: LearningRateScheduler reducing learning rate to 0.01001953125.
Epoch 10/20
254/254 [==============================] - 1s 6ms/step - loss: 0.3260 -
accuracy: 0.8466 - val\_loss: 0.3361 - val\_accuracy: 0.8484

Epoch 00011: LearningRateScheduler reducing learning rate to 0.010009765625.
Epoch 11/20
254/254 [==============================] - 2s 8ms/step - loss: 0.3270 -
accuracy: 0.8467 - val\_loss: 0.3286 - val\_accuracy: 0.8478

Epoch 00012: LearningRateScheduler reducing learning rate to
0.010004882812500001.
Epoch 12/20
254/254 [==============================] - 2s 8ms/step - loss: 0.3263 -
accuracy: 0.8494 - val\_loss: 0.3217 - val\_accuracy: 0.8499

Epoch 00013: LearningRateScheduler reducing learning rate to 0.01000244140625.
Epoch 13/20
254/254 [==============================] - 2s 8ms/step - loss: 0.3253 -
accuracy: 0.8496 - val\_loss: 0.3256 - val\_accuracy: 0.8511

Epoch 00014: LearningRateScheduler reducing learning rate to 0.010001220703125.
Epoch 14/20
254/254 [==============================] - 1s 5ms/step - loss: 0.3249 -
accuracy: 0.8499 - val\_loss: 0.3281 - val\_accuracy: 0.8528

Epoch 00015: LearningRateScheduler reducing learning rate to 0.0100006103515625.
Epoch 15/20
254/254 [==============================] - 2s 9ms/step - loss: 0.3269 -
accuracy: 0.8494 - val\_loss: 0.3377 - val\_accuracy: 0.8472

Epoch 00016: LearningRateScheduler reducing learning rate to
0.01000030517578125.
Epoch 16/20
254/254 [==============================] - 2s 6ms/step - loss: 0.3234 -
accuracy: 0.8495 - val\_loss: 0.3292 - val\_accuracy: 0.8532

Epoch 00017: LearningRateScheduler reducing learning rate to
0.010000152587890625.
Epoch 17/20
254/254 [==============================] - 2s 8ms/step - loss: 0.3258 -
accuracy: 0.8491 - val\_loss: 0.3288 - val\_accuracy: 0.8531

Epoch 00018: LearningRateScheduler reducing learning rate to
0.010000076293945313.
Epoch 18/20
254/254 [==============================] - 2s 8ms/step - loss: 0.3252 -
accuracy: 0.8504 - val\_loss: 0.3320 - val\_accuracy: 0.8534

Epoch 00019: LearningRateScheduler reducing learning rate to
0.010000038146972657.
Epoch 19/20
254/254 [==============================] - 2s 7ms/step - loss: 0.3270 -
accuracy: 0.8498 - val\_loss: 0.3418 - val\_accuracy: 0.8480

Epoch 00020: LearningRateScheduler reducing learning rate to
0.010000019073486329.
Epoch 20/20
254/254 [==============================] - 1s 6ms/step - loss: 0.3264 -
accuracy: 0.8499 - val\_loss: 0.3255 - val\_accuracy: 0.8518
Model exported to: output/keras\_export
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
2021-08-21 20:08:58.046125: I
tensorflow/core/platform/profile\_utils/cpu\_utils.cc:104] CPU Frequency:
2299995000 Hz
2021-08-21 20:08:58.046516: I tensorflow/compiler/xla/service/service.cc:168]
XLA service 0x5598d4aca0b0 initialized for platform Host (this does not
guarantee that XLA will be used). Devices:
2021-08-21 20:08:58.046543: I tensorflow/compiler/xla/service/service.cc:176]
StreamExecutor device (0): Host, Default Version
2021-08-21 20:08:58.048848: I
tensorflow/core/common\_runtime/process\_util.cc:146] Creating new thread pool
with default inter op setting: 2. Tune using inter\_op\_parallelism\_threads for
best performance.
WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not
using nccl allreduce.
2021-08-21 20:08:59.141659: I
tensorflow/core/profiler/lib/profiler\_session.cc:164] Profiler session started.
WARNING:tensorflow:From /opt/conda/lib/python3.7/site-
packages/tensorflow/python/data/ops/multi\_device\_iterator\_ops.py:601:
get\_next\_as\_optional (from tensorflow.python.data.ops.iterator\_ops) is
deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Iterator.get\_next\_as\_optional()` instead.
2021-08-21 20:09:02.976662: I
tensorflow/core/profiler/lib/profiler\_session.cc:164] Profiler session started.
WARNING:tensorflow:From /opt/conda/lib/python3.7/site-
packages/tensorflow/python/ops/summary\_ops\_v2.py:1277: stop (from
tensorflow.python.eager.profiler) is deprecated and will be removed after
2020-07-01.
Instructions for updating:
use `tf.profiler.experimental.stop` instead.
2021-08-21 20:09:03.020157: I
tensorflow/core/profiler/rpc/client/save\_profile.cc:176] Creating directory:
output/keras\_tensorboard/train/plugins/profile/2021\_08\_21\_20\_09\_03
2021-08-21 20:09:03.026749: I
tensorflow/core/profiler/rpc/client/save\_profile.cc:182] Dumped gzipped tool
data for trace.json.gz to output/keras\_tensorboard/train/plugins/profile/2021\_08
\_21\_20\_09\_03/tensorflow-2-3-20210821-160118.trace.json.gz
2021-08-21 20:09:03.046996: I
tensorflow/core/profiler/rpc/client/save\_profile.cc:176] Creating directory:
output/keras\_tensorboard/train/plugins/profile/2021\_08\_21\_20\_09\_03
2021-08-21 20:09:03.049117: I
tensorflow/core/profiler/rpc/client/save\_profile.cc:182] Dumped gzipped tool
data for memory\_profile.json.gz to output/keras\_tensorboard/train/plugins/profil
e/2021\_08\_21\_20\_09\_03/tensorflow-2-3-20210821-160118.memory\_profile.json.gz
2021-08-21 20:09:03.051295: I
tensorflow/python/profiler/internal/profiler\_wrapper.cc:111] Creating directory:
output/keras\_tensorboard/train/plugins/profile/2021\_08\_21\_20\_09\_03Dumped tool
data for xplane.pb to output/keras\_tensorboard/train/plugins/profile/2021\_08\_21\_
20\_09\_03/tensorflow-2-3-20210821-160118.xplane.pb
Dumped tool data for overview\_page.pb to output/keras\_tensorboard/train/plugins/
profile/2021\_08\_21\_20\_09\_03/tensorflow-2-3-20210821-160118.overview\_page.pb
Dumped tool data for input\_pipeline.pb to output/keras\_tensorboard/train/plugins
/profile/2021\_08\_21\_20\_09\_03/tensorflow-2-3-20210821-160118.input\_pipeline.pb
Dumped tool data for tensorflow\_stats.pb to output/keras\_tensorboard/train/plugi
ns/profile/2021\_08\_21\_20\_09\_03/tensorflow-2-3-20210821-160118.tensorflow\_stats.p
b
Dumped tool data for kernel\_stats.pb to output/keras\_tensorboard/train/plugins/p
rofile/2021\_08\_21\_20\_09\_03/tensorflow-2-3-20210821-160118.kernel\_stats.pb

WARNING:tensorflow:Callbacks method `on\_train\_batch\_end` is slow compared to the
batch time (batch time: 0.0137s vs `on\_train\_batch\_end` time: 0.0635s). Check
your callbacks.
WARNING:tensorflow:From /opt/conda/lib/python3.7/site-
packages/tensorflow/python/training/tracking/tracking.py:111:
Model.state\_updates (from tensorflow.python.keras.engine.training) is deprecated
and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied
automatically.
2021-08-21 20:09:40.692978: W tensorflow/python/util/util.cc:348] Sets are not
currently considered sequences, but this may change in the future, so consider
avoiding using them.
WARNING:tensorflow:From /opt/conda/lib/python3.7/site-
packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates
(from tensorflow.python.keras.engine.base\_layer) is deprecated and will be
removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied
automatically.
INFO:tensorflow:Assets written to: output/keras\_export/assets
    \end{Verbatim}

    Check if the output has been written to the output folder:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{bash}

ls output/keras\PYZus{}export/
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
assets
saved\_model.pb
variables
    \end{Verbatim}

    \hypertarget{step-2.3-prepare-input-for-prediction}{%
\paragraph{Step 2.3: Prepare input for
prediction}\label{step-2.3-prepare-input-for-prediction}}

To receive valid and useful predictions, you must preprocess input for
prediction in the same way that training data was preprocessed. In a
production system, you may want to create a preprocessing pipeline that
can be used identically at training time and prediction time.

For this exercise, use the training package's data-loading code to
select a random sample from the evaluation data. This data is in the
form that was used to evaluate accuracy after each epoch of training, so
it can be used to send test predictions without further preprocessing.

    Run the following snippet of code to preprocess the raw data from the
adult.test.csv file. Here, we are grabbing 5 examples to run predictions
on:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{trainer} \PY{k+kn}{import} \PY{n}{util}
\PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{eval\PYZus{}x}\PY{p}{,} \PY{n}{eval\PYZus{}y} \PY{o}{=} \PY{n}{util}\PY{o}{.}\PY{n}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}

\PY{n}{prediction\PYZus{}input} \PY{o}{=} \PY{n}{eval\PYZus{}x}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}
\PY{n}{prediction\PYZus{}targets} \PY{o}{=} \PY{n}{eval\PYZus{}y}\PY{p}{[}\PY{n}{prediction\PYZus{}input}\PY{o}{.}\PY{n}{index}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    Check the numerical representation of the features by printing the
preprocessed data:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{12}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{n}{prediction\PYZus{}input}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
           age  workclass  education\_num  marital\_status  occupation  \textbackslash{}
6523  0.682402          3       1.136850               2          11
399   0.463600          3       1.136850               2           3
8292 -0.338673          5       0.358743               2           4
7957  1.776411          3      -0.419365               2          13
3814  0.463600          3      -0.419365               2          11

      relationship  race  capital\_gain  capital\_loss  hours\_per\_week  \textbackslash{}
6523             0     4     13.275268     -0.217119        3.194347
399              0     4     -0.144807     -0.217119       -0.034043
8292             0     4     -0.144807     -0.217119        0.773054
7957             0     4     -0.144807     -0.217119       -0.034043
3814             0     4     -0.144807     -0.217119        1.176603

      native\_country
6523              38
399               38
8292              38
7957              38
3814              38
    \end{Verbatim}

    Notice that categorical fields, like occupation, have already been
converted to integers (with the same mapping that was used for
training). Numerical fields, like age, have been scaled to a z-score.
Some fields have been dropped from the original data.

Export the prediction input to a newline-delimited JSON file:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{json}

\PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{w}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{json\PYZus{}file}\PY{p}{:}
  \PY{k}{for} \PY{n}{row} \PY{o+ow}{in} \PY{n}{prediction\PYZus{}input}\PY{o}{.}\PY{n}{values}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{n}{json}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{n}{row}\PY{p}{,} \PY{n}{json\PYZus{}file}\PY{p}{)}
    \PY{n}{json\PYZus{}file}\PY{o}{.}\PY{n}{write}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    Inspect the .json file:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{bash}

cat test.json
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[0.6824020743370056, 3.0, 1.1368497610092163, 2.0, 11.0, 0.0, 4.0,
13.275267601013184, -0.2171185314655304, 3.1943466663360596, 38.0]
[0.46360018849372864, 3.0, 1.1368497610092163, 2.0, 3.0, 0.0, 4.0,
-0.14480669796466827, -0.2171185314655304, -0.034042954444885254, 38.0]
[-0.3386733829975128, 5.0, 0.3587425947189331, 2.0, 4.0, 0.0, 4.0,
-0.14480669796466827, -0.2171185314655304, 0.7730544209480286, 38.0]
[1.7764114141464233, 3.0, -0.4193645119667053, 2.0, 13.0, 0.0, 4.0,
-0.14480669796466827, -0.2171185314655304, -0.034042954444885254, 38.0]
[0.46360018849372864, 3.0, -0.4193645119667053, 2.0, 11.0, 0.0, 4.0,
-0.14480669796466827, -0.2171185314655304, 1.176603078842163, 38.0]
    \end{Verbatim}

    \hypertarget{step-2.4-use-your-trained-model-for-prediction}{%
\paragraph{Step 2.4: Use your trained model for
prediction}\label{step-2.4-use-your-trained-model-for-prediction}}

Once you've trained your TensorFlow model, you can use it for prediction
on new data. In this case, you've trained a census model to predict
income category given some information about a person.

Run the following command to run prediction on the test.json file we
created above:

    \textbf{Note:} If you get a ``Bad magic number in .pyc file'' error, go
to the terminal and run: \textgreater{} cd
../../usr/lib/google-cloud-sdk/lib/googlecloudsdk/command\_lib/ml\_engine/

\begin{quote}
sudo rm *.pyc
\end{quote}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{bash}

gcloud ai\PYZhy{}platform local predict \PYZbs{}
    \PYZhy{}\PYZhy{}model\PYZhy{}dir output/keras\PYZus{}export/ \PYZbs{}
    \PYZhy{}\PYZhy{}json\PYZhy{}instances ./test.json
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
DENSE\_4
[1.0]
[0.7361040711402893]
[0.4700159728527069]
[0.3878123462200165]
[0.5061850547790527]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
If the signature defined in the model is not serving\_default then you must
specify it via --signature-name flag, otherwise the command may fail.
WARNING: WARNING:tensorflow:From /opt/conda/lib/python3.7/site-
packages/tensorflow/python/compat/v2\_compat.py:96: disable\_resource\_variables
(from tensorflow.python.ops.variable\_scope) is deprecated and will be removed in
a future version.
Instructions for updating:
non-resource variables are not supported in the long term
2021-08-21 20:10:28.673693: I
tensorflow/core/platform/profile\_utils/cpu\_utils.cc:104] CPU Frequency:
2299995000 Hz
2021-08-21 20:10:28.673996: I tensorflow/compiler/xla/service/service.cc:168]
XLA service 0x55a4f93d4440 initialized for platform Host (this does not
guarantee that XLA will be used). Devices:
2021-08-21 20:10:28.674019: I tensorflow/compiler/xla/service/service.cc:176]
StreamExecutor device (0): Host, Default Version
2021-08-21 20:10:28.674146: I
tensorflow/core/common\_runtime/process\_util.cc:146] Creating new thread pool
with default inter op setting: 2. Tune using inter\_op\_parallelism\_threads for
best performance.
WARNING:tensorflow:From /usr/lib/google-cloud-sdk/lib/third\_party/ml\_sdk/cloud/m
l/prediction/frameworks/tf\_prediction\_lib.py:236: load (from
tensorflow.python.saved\_model.loader\_impl) is deprecated and will be removed in
a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as
tf.compat.v1.saved\_model.loader.load or tf.compat.v1.saved\_model.load. There
will be a new function for importing SavedModels in Tensorflow 2.0.
WARNING:tensorflow:From /usr/lib/google-cloud-sdk/lib/third\_party/ml\_sdk/cloud/m
l/prediction/frameworks/tf\_prediction\_lib.py:236: load (from
tensorflow.python.saved\_model.loader\_impl) is deprecated and will be removed in
a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as
tf.compat.v1.saved\_model.loader.load or tf.compat.v1.saved\_model.load. There
will be a new function for importing SavedModels in Tensorflow 2.0.
WARNING:root:Error updating signature \_\_saved\_model\_init\_op: The name 'NoOp'
refers to an Operation, not a Tensor. Tensor names must be of the form
"<op\_name>:<output\_index>".

    \end{Verbatim}

    Since the model's last layer uses a sigmoid function for its activation,
outputs between 0 and 0.5 represent negative predictions
\textbf{(``\textless=50K'')} and outputs between 0.5 and 1 represent
positive ones \textbf{(``\textgreater50K'')}.

    \hypertarget{step-3-run-your-training-job-in-the-cloud}{%
\subsubsection{Step 3: Run your training job in the
cloud}\label{step-3-run-your-training-job-in-the-cloud}}

Now that you've validated your model by running it locally, you will now
get practice training using Cloud AI Platform.

\textbf{Note:} The initial job request will take several minutes to
start, but subsequent jobs run more quickly. This enables quick
iteration as you develop and validate your training job.

First, set the following variables:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{bash}
export PROJECT=\PYZdl{}(gcloud config list project \PYZhy{}\PYZhy{}format \PYZdq{}value(core.project)\PYZdq{})
echo \PYZdq{}Your current GCP Project Name is: \PYZdq{}\PYZdl{}\PYZob{}PROJECT\PYZcb{}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Your current GCP Project Name is: qwiklabs-gcp-04-1e5e10b85531
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{22}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{PROJECT} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{qwiklabs\PYZhy{}gcp\PYZhy{}04\PYZhy{}1e5e10b85531}\PY{l+s+s2}{\PYZdq{}}  \PY{c+c1}{\PYZsh{} Replace with your project name}
\PY{n}{BUCKET\PYZus{}NAME}\PY{o}{=}\PY{n}{PROJECT}\PY{o}{+}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZhy{}aiplatform}\PY{l+s+s2}{\PYZdq{}}
\PY{n}{REGION}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{us\PYZhy{}central1}\PY{l+s+s2}{\PYZdq{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{23}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{os}\PY{o}{.}\PY{n}{environ}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PROJECT}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{PROJECT}
\PY{n}{os}\PY{o}{.}\PY{n}{environ}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{BUCKET\PYZus{}NAME}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{BUCKET\PYZus{}NAME}
\PY{n}{os}\PY{o}{.}\PY{n}{environ}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{REGION}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{REGION}
\PY{n}{os}\PY{o}{.}\PY{n}{environ}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TFVERSION}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{2.1}\PY{l+s+s2}{\PYZdq{}}
\PY{n}{os}\PY{o}{.}\PY{n}{environ}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PYTHONVERSION}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{3.7}\PY{l+s+s2}{\PYZdq{}}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{step-3.1-set-up-a-cloud-storage-bucket}{%
\paragraph{Step 3.1: Set up a Cloud Storage
bucket}\label{step-3.1-set-up-a-cloud-storage-bucket}}

The AI Platform services need to access Cloud Storage (GCS) to read and
write data during model training and batch prediction.

Create a bucket using BUCKET\_NAME as the name for the bucket and copy
the data into it.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{24}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{bash}

if ! gsutil ls | grep \PYZhy{}q gs://\PYZdl{}\PYZob{}BUCKET\PYZus{}NAME\PYZcb{}; then
    gsutil mb \PYZhy{}l \PYZdl{}\PYZob{}REGION\PYZcb{} gs://\PYZdl{}\PYZob{}BUCKET\PYZus{}NAME\PYZcb{}
fi
gsutil cp \PYZhy{}r data gs://\PYZdl{}BUCKET\PYZus{}NAME/data
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Creating gs://qwiklabs-gcp-04-1e5e10b85531-aiplatform/{\ldots}
Copying file://data/census.test.csv [Content-Type=text/csv]{\ldots}
Copying file://data/adult.test.csv [Content-Type=text/csv]{\ldots}
Copying file://data/test.csv [Content-Type=text/csv]{\ldots}
Copying file://data/adult.data.csv [Content-Type=text/csv]{\ldots}
- [4 files][  7.4 MiB/  7.4 MiB]
==> NOTE: You are performing a sequence of gsutil operations that may
run significantly faster if you instead use gsutil -m cp {\ldots} Please
see the -m section under "gsutil help options" for further information
about when gsutil -m can be advantageous.

Copying file://data/census.train.csv [Content-Type=text/csv]{\ldots}
Copying file://data/test.json [Content-Type=application/json]{\ldots}
\textbackslash{} [6 files][ 10.7 MiB/ 10.7 MiB]
Operation completed over 6 objects/10.7 MiB.
    \end{Verbatim}

    Set the TRAIN\_DATA and EVAL\_DATA variables to point to the files:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{25}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{bash}

export TRAIN\PYZus{}DATA=gs://\PYZdl{}BUCKET\PYZus{}NAME/data/adult.data.csv
export EVAL\PYZus{}DATA=gs://\PYZdl{}BUCKET\PYZus{}NAME/data/adult.test.csv
\end{Verbatim}
\end{tcolorbox}

    Use gsutil again to copy the JSON test file test.json to your Cloud
Storage bucket:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{26}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{bash}

gsutil cp test.json gs://\PYZdl{}BUCKET\PYZus{}NAME/data/test.json
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Copying file://test.json [Content-Type=application/json]{\ldots}
/ [1 files][  686.0 B/  686.0 B]
Operation completed over 1 objects/686.0 B.
    \end{Verbatim}

    Set the TEST\_JSON variable to point to that file:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{27}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{bash}

export TEST\PYZus{}JSON=gs://\PYZdl{}BUCKET\PYZus{}NAME/data/test.json
\end{Verbatim}
\end{tcolorbox}

    \textbf{Go back to the lab instructions and check your progress by
testing the completed tasks:}

\textbf{- ``Set up a Google Cloud Storage''.}

\textbf{- ``Upload the data files to your Cloud Storage bucket''.}

    \hypertarget{step-3.2-run-a-single-instance-trainer-in-the-cloud}{%
\paragraph{Step 3.2: Run a single-instance trainer in the
cloud}\label{step-3.2-run-a-single-instance-trainer-in-the-cloud}}

With a validated training job that runs in both single-instance and
distributed mode, you're now ready to run a training job in the cloud.
For this example, we will be requesting a single-instance training job.

Use the default BASIC scale tier to run a single-instance training job.
The initial job request can take a few minutes to start, but subsequent
jobs run more quickly. This enables quick iteration as you develop and
validate your training job.

Select a name for the initial training run that distinguishes it from
any subsequent training runs. For example, we can use date and time to
compose the job id.

Specify a directory for output generated by AI Platform by setting an
OUTPUT\_PATH variable to include when requesting training and prediction
jobs. The OUTPUT\_PATH represents the fully qualified Cloud Storage
location for model checkpoints, summaries, and exports. You can use the
BUCKET\_NAME variable you defined in a previous step. It's a good
practice to use the job name as the output directory.

Run the following command to submit a training job in the cloud that
uses a single process. This time, set the --verbosity tag to DEBUG so
that you can inspect the full logging output and retrieve accuracy,
loss, and other metrics. The output also contains a number of other
warning messages that you can ignore for the purposes of this sample:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{34}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{bash}

JOB\PYZus{}ID=census\PYZus{}\PYZdl{}(date \PYZhy{}u +\PYZpc{}y\PYZpc{}m\PYZpc{}d\PYZus{}\PYZpc{}H\PYZpc{}M\PYZpc{}S)
OUTPUT\PYZus{}PATH=gs://\PYZdl{}BUCKET\PYZus{}NAME/\PYZdl{}JOB\PYZus{}ID
gcloud ai\PYZhy{}platform jobs submit training \PYZdl{}JOB\PYZus{}ID \PYZbs{}
    \PYZhy{}\PYZhy{}job\PYZhy{}dir \PYZdl{}OUTPUT\PYZus{}PATH \PYZbs{}
    \PYZhy{}\PYZhy{}runtime\PYZhy{}version \PYZdl{}TFVERSION \PYZbs{}
    \PYZhy{}\PYZhy{}python\PYZhy{}version \PYZdl{}PYTHONVERSION \PYZbs{}
    \PYZhy{}\PYZhy{}module\PYZhy{}name trainer.task \PYZbs{}
    \PYZhy{}\PYZhy{}package\PYZhy{}path trainer/ \PYZbs{}
    \PYZhy{}\PYZhy{}region \PYZdl{}REGION \PYZbs{}
    \PYZhy{}\PYZhy{} \PYZbs{}
    \PYZhy{}\PYZhy{}train\PYZhy{}files \PYZdl{}TRAIN\PYZus{}DATA \PYZbs{}
    \PYZhy{}\PYZhy{}eval\PYZhy{}files \PYZdl{}EVAL\PYZus{}DATA \PYZbs{}
    \PYZhy{}\PYZhy{}train\PYZhy{}steps 1000 \PYZbs{}
    \PYZhy{}\PYZhy{}eval\PYZhy{}steps 100 \PYZbs{}
    \PYZhy{}\PYZhy{}verbosity DEBUG
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
jobId: census\_210821\_201659
state: QUEUED
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Job [census\_210821\_201659] submitted successfully.
Your job is still active. You may view the status of your job with the command

  \$ gcloud ai-platform jobs describe census\_210821\_201659

or continue streaming the logs with the command

  \$ gcloud ai-platform jobs stream-logs census\_210821\_201659
    \end{Verbatim}

    Set an environment variable with the jobId generated above:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{39}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{os}\PY{o}{.}\PY{n}{environ}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{JOB\PYZus{}ID}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{census\PYZus{}210821\PYZus{}201659}\PY{l+s+s2}{\PYZdq{}} \PY{c+c1}{\PYZsh{} Replace with your job id}
\end{Verbatim}
\end{tcolorbox}

    You can monitor the progress of your training job by watching the logs
on the command line by running:

\texttt{gcloud\ ai-platform\ jobs\ stream-logs\ \$JOB\_ID}

Or monitor it in the Console at
\texttt{AI\ Platform\ \textgreater{}\ Jobs}. Wait until your AI Platform
training job is done. It is finished when you see a green check mark by
the jobname in the Cloud Console, or when you see the message Job
completed successfully from the Cloud Shell command line.

    \textbf{Go back to the lab instructions and check your progress by
testing the completed task:}

\textbf{- ``Run a single-instance trainer in the cloud''.}

    \hypertarget{step-3.3-deploy-your-model-to-support-prediction}{%
\paragraph{Step 3.3: Deploy your model to support
prediction}\label{step-3.3-deploy-your-model-to-support-prediction}}

By deploying your trained model to AI Platform to serve online
prediction requests, you get the benefit of scalable serving. This is
useful if you expect your trained model to be hit with many prediction
requests in a short period of time.

Create an AI Platform model:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{42}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{os}\PY{o}{.}\PY{n}{environ}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{MODEL\PYZus{}NAME}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{census\PYZus{}20210821}\PY{l+s+s2}{\PYZdq{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{43}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{bash}

gcloud ai\PYZhy{}platform models create \PYZdl{}MODEL\PYZus{}NAME \PYZhy{}\PYZhy{}regions=\PYZdl{}REGION
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Using endpoint [https://ml.googleapis.com/]
Created ai platform model [projects/qwiklabs-
gcp-04-1e5e10b85531/models/census\_20210821].
    \end{Verbatim}

    Set the environment variable MODEL\_BINARIES to the full path of your
exported trained model binaries \texttt{\$OUTPUT\_PATH/keras\_export/}.

    You'll deploy this trained model.

Run the following command to create a version v1 of your model:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{44}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{bash}

OUTPUT\PYZus{}PATH=gs://\PYZdl{}BUCKET\PYZus{}NAME/\PYZdl{}JOB\PYZus{}ID
MODEL\PYZus{}BINARIES=\PYZdl{}OUTPUT\PYZus{}PATH/keras\PYZus{}export/
gcloud ai\PYZhy{}platform versions create v1 \PYZbs{}
\PYZhy{}\PYZhy{}model \PYZdl{}MODEL\PYZus{}NAME \PYZbs{}
\PYZhy{}\PYZhy{}origin \PYZdl{}MODEL\PYZus{}BINARIES \PYZbs{}
\PYZhy{}\PYZhy{}runtime\PYZhy{}version \PYZdl{}TFVERSION \PYZbs{}
\PYZhy{}\PYZhy{}python\PYZhy{}version \PYZdl{}PYTHONVERSION \PYZbs{}
\PYZhy{}\PYZhy{}region=global
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Using endpoint [https://ml.googleapis.com/]
Creating version (this might take a few minutes){\ldots}
{\ldots}
{\ldots}
{\ldots}
{\ldots}
{\ldots}
{\ldots}
{\ldots}
{\ldots}
{\ldots}
{\ldots}done.
    \end{Verbatim}

    It may take several minutes to deploy your trained model. When done, you
can see a list of your models using the models list command:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{45}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{bash}

gcloud ai\PYZhy{}platform models list
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Using endpoint [https://us-central1-ml.googleapis.com/]
Listed 0 items.
    \end{Verbatim}

    \textbf{Go back to the lab instructions and check your progress by
testing the completed tasks:}

\textbf{- ``Create an AI Platform model''.}

\textbf{- ``Create a version v1 of your model''.}

    \hypertarget{step-3.4-send-an-online-prediction-request-to-your-deployed-model}{%
\paragraph{Step 3.4: Send an online prediction request to your deployed
model}\label{step-3.4-send-an-online-prediction-request-to-your-deployed-model}}

You can now send prediction requests to your deployed model. The
following command sends a prediction request using the test.json.

The response includes the probabilities of each label
\textbf{(\textgreater50K and \textless=50K)} based on the data entry in
test.json, thus indicating whether the predicted income is greater than
or less than 50,000 dollars.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{46}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{bash}

gcloud ai\PYZhy{}platform predict \PYZbs{}
\PYZhy{}\PYZhy{}model \PYZdl{}MODEL\PYZus{}NAME \PYZbs{}
\PYZhy{}\PYZhy{}version v1 \PYZbs{}
\PYZhy{}\PYZhy{}json\PYZhy{}instances ./test.json \PYZbs{}
\PYZhy{}\PYZhy{}region global
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
DENSE\_4
[1.0]
[0.696794331073761]
[0.5728724002838135]
[0.398429811000824]
[0.5790835618972778]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Using endpoint [https://ml.googleapis.com/]
    \end{Verbatim}

    \textbf{Note:} AI Platform supports batch prediction, too, but it's not
included in this lab. See the documentation for more info.

    \textbf{Go back to the lab instructions to answer some multiple choice
questions to reinforce your uncerstanding of some of these lab's
concepts.}

    \hypertarget{congratulations}{%
\subsubsection{Congratulations!}\label{congratulations}}

In this lab you've learned how to train a TensorFlow model both locally
and on AI Platform, how to prepare data for prediction and to perform
predictions both locally and in the Cloud AI Platform.


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
